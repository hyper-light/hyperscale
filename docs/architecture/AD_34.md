---
ad_number: 34
name: Adaptive Job Timeout with Multi-DC Coordination
description: Adaptive timeout architecture that auto-detects deployment topology and coordinates timeouts across datacenters
---

# AD-34: Adaptive Job Timeout with Multi-DC Coordination

## Overview

Jobs need timeout protection to prevent resource leaks when workers are alive but workflows are stuck. The challenge: **the same job may execute in multiple datacenters simultaneously**, requiring coordinated timeout detection and cancellation.

AD-34 provides an **adaptive timeout architecture** that:
- Auto-detects deployment topology (single-DC vs multi-DC)
- Uses **local authority** for single-DC (manager decides)
- Uses **gate coordination** for multi-DC (gate decides globally)
- Handles leader failures, network partitions, and race conditions
- Detects both "overall timeout" and "workflows stuck but worker alive"

---

## Problem Statement

### Timeout Scenarios

1. **Overall Job Timeout**: Job exceeds `timeout_seconds` from submission
2. **Stuck Workflows**: Worker alive but workflows making no progress
3. **Multi-DC Consistency**: In multi-DC, if DC-A times out, DC-B/C should be cancelled
4. **Worker vs Workflow Failure**: Worker heartbeat OK, but workflow stuck

### Challenges

1. **Multi-DC Coordination**: How does DC-A timeout trigger cancellation in DC-B/C?
2. **Topology Flexibility**: System must work in both single-DC and multi-DC
3. **Fault Tolerance**: Leader failures, gate failures, network partitions
4. **Race Conditions**: Job completes while timeout is being declared
5. **State Recovery**: New leader must resume timeout tracking

---

## Part 1: Architecture Overview

### Deployment Topologies

```
+---------------------------------------------------------------------+
|                     Single-DC Deployment                             |
+---------------------------------------------------------------------+

Client -> Manager Leader -> Workers
              |
         (Local Authority)
         Directly marks job
         as timed out


+---------------------------------------------------------------------+
|                     Multi-DC Deployment                              |
+---------------------------------------------------------------------+

                    Client
                      |
                    Gate (Global Authority)
                      |
        +-------------+-------------+
        |             |             |
      DC-A          DC-B          DC-C
    Manager       Manager       Manager
    (Reports)     (Reports)     (Reports)
        |             |             |
    Workers       Workers       Workers

Gate receives timeout reports from each DC
Gate declares global timeout
Gate cancels job in ALL DCs
```

### Auto-Detection Pattern

**Strategy selected per-job based on JobSubmission:**

```python
if job_submission.gate_addr is not None:
    # Multi-DC: Gate submitted job
    strategy = GateCoordinatedTimeout(manager)
else:
    # Single-DC: Client submitted directly
    strategy = LocalAuthorityTimeout(manager)
```

No configuration needed! System adapts automatically.

---

## Part 2: Core Components

### Timeout Tracking State (Persistent)

```python
@dataclass
class TimeoutTrackingState:
    """
    Timeout tracking state persisted in JobInfo.

    Survives leader transfers via state sync - new leader
    inherits this state and resumes timeout tracking.
    """
    strategy_type: str  # "local_authority" | "gate_coordinated"
    gate_addr: tuple[str, int] | None  # Where to report (multi-DC only)

    # Timestamps (absolute, monotonic)
    started_at: float  # When job started (never changes)
    last_progress_at: float  # Last workflow progress
    last_report_at: float  # Last progress report to gate (multi-DC only)

    # Timeout configuration
    timeout_seconds: float
    stuck_threshold: float = 120.0  # No progress threshold (2 minutes)

    # State flags (idempotency)
    locally_timed_out: bool = False  # Manager reported timeout to gate
    globally_timed_out: bool = False  # Gate declared global timeout
    timeout_reason: str = ""

    # Fencing (prevent stale decisions)
    timeout_fence_token: int = 0  # Incremented on leader transfer
```

**Key Design Points:**

1. **Stored in JobInfo**: Survives leader failures (transferred via state sync)
2. **Absolute Timestamps**: `started_at` never changes, enables timeout calculation after leader transfer
3. **Idempotency Flags**: `locally_timed_out` prevents duplicate timeout reports
4. **Fence Tokens**: Prevent stale timeout decisions after leader transfer

### Timeout Strategy Interface

```python
class TimeoutStrategy(ABC):
    """Base timeout strategy with state recovery."""

    @abstractmethod
    async def start_tracking(
        self,
        job_id: str,
        timeout_seconds: float,
        gate_addr: tuple[str, int] | None = None
    ) -> None:
        """Start tracking on job submission."""
        pass

    @abstractmethod
    async def resume_tracking(self, job_id: str) -> None:
        """
        Resume tracking after leader transfer.

        CRITICAL: New leader calls this to continue timeout tracking.
        Reconstructs strategy state from JobInfo.timeout_tracking.
        """
        pass

    @abstractmethod
    async def report_progress(self, job_id: str, progress_type: str) -> None:
        """Record workflow progress event."""
        pass

    @abstractmethod
    async def check_timeout(self, job_id: str) -> tuple[bool, str]:
        """
        Check if job timed out.

        Returns (is_timed_out, reason).
        Idempotent - safe to call multiple times.
        """
        pass

    @abstractmethod
    async def handle_global_timeout(
        self,
        job_id: str,
        reason: str,
        fence_token: int
    ) -> bool:
        """
        Handle global timeout decision from gate.

        Returns True if accepted, False if rejected (stale).
        """
        pass
```

---

## Part 3: Strategy 1 - Local Authority (Single-DC)

### Overview

**When**: No gate involved (direct client -> manager submission)
**Authority**: Manager leader has full timeout authority
**Behavior**: Manager directly marks job as timed out

### State Diagram - Local Authority

```
Job Submitted
     |
TimeoutTrackingState created
  started_at = now
  locally_timed_out = False
     |
+===================================+
|    Periodic Timeout Checks        |
|    (every 30s, leader only)       |
+===================================+
     |
+---------------------------------+
| Check 1: Overall Timeout        |
| elapsed > timeout_seconds?      |
+---------------------------------+
     | YES                    | NO
  Mark timed out           Continue
  Call _timeout_job()         |
                        +---------------------------------+
                        | Check 2: Stuck Detection        |
                        | (now - last_progress_at) > 120s?|
                        +---------------------------------+
                             | YES              | NO
                          Mark stuck         Keep tracking
                          Call _timeout_job()   |
                                            Resume loop

Leader Failure -> New Leader -> resume_tracking() -> Continue from same state
```

---

## Part 4: Strategy 2 - Gate Coordinated (Multi-DC)

### Overview

**When**: Gate submitted job (`gate_addr` in JobSubmission)
**Authority**: Gate has global timeout authority
**Manager Role**: Detect local timeouts, report to gate
**Gate Role**: Collect reports from all DCs, declare global timeout, broadcast cancellation

### State Diagram - Gate Coordinated (Manager)

```
Job Submitted (with gate_addr)
     |
TimeoutTrackingState created
  strategy = "gate_coordinated"
  gate_addr = <gate>
     |
+===================================+
|  Periodic Checks (every 30s)      |
+===================================+
     |
Send Progress Report (every 10s)
     | (best-effort)
   Gate
     |
Check DC-Local Timeout
     | TIMEOUT DETECTED
Send Timeout Report to Gate
  locally_timed_out = True
     |
+===================================+
|    Wait for Gate Decision         |
|  (or 5min fallback timeout)       |
+===================================+
     |
  +-------------+-------------+
  |              |              |
Gate            Gate         5min passed
Says            Unresponsive  No response
Timeout                       |
  |                          Local
Mark                         Fallback
globally_timed_out           Timeout
  |                            |
_timeout_job()           _timeout_job()
```

---

## Part 5: Gate Global Timeout Coordination

### Gate Job Tracker

```python
@dataclass
class GateJobTrackingInfo:
    """Gate's view of a job across all DCs."""
    job_id: str
    submitted_at: float  # Global start time
    timeout_seconds: float
    target_datacenters: list[str]  # Which DCs running this job

    # Per-DC state
    dc_status: dict[str, str]  # dc_name -> "running" | "completed" | "timed_out"
    dc_last_progress: dict[str, float]  # dc_name -> last progress timestamp
    dc_manager_addrs: dict[str, tuple[str, int]]  # dc_name -> manager addr

    # Global timeout decision
    globally_timed_out: bool = False
    timeout_reason: str = ""
    timeout_fence_token: int = 0  # Gate's fence token for this decision
```

### State Diagram - Gate Global Coordinator

```
Job Submitted to Multiple DCs
     |
GateJobTrackingInfo created
  dc_status = {A: "running", B: "running", C: "running"}
     |
+===================================+
|   Receive Reports from DCs        |
|   - Progress (every 10s)          |
|   - Timeout (when detected)       |
+===================================+
     |
Update dc_last_progress[dc]
Update dc_status[dc]
     |
+===================================+
|  Periodic Global Timeout Check    |
|      (every 15s)                  |
+===================================+
     |
Check 3 Conditions:
  1. Global timeout exceeded?
  2. Any DC reported timeout?
  3. All DCs stuck (no progress 3+ min)?
     | ANY TRUE
Declare Global Timeout
  globally_timed_out = True
  timeout_fence_token++
     |
Broadcast JobGlobalTimeout to ALL DCs
     |
   DC-A         DC-B         DC-C
     |           |            |
  Cancel      Cancel       Cancel
   Job         Job          Job
```

---

## Part 6: Protocol Messages

### JobProgressReport

```python
@dataclass
class JobProgressReport(Message):
    """Manager -> Gate: Periodic progress report."""
    job_id: str
    datacenter: str
    manager_id: str
    manager_host: str  # For gate to send replies
    manager_port: int
    workflows_total: int
    workflows_completed: int
    workflows_failed: int
    has_recent_progress: bool  # Any workflow progressed in last 10s
    timestamp: float
    fence_token: int  # Manager's fence token
```

### JobTimeoutReport

```python
@dataclass
class JobTimeoutReport(Message):
    """Manager -> Gate: DC-local timeout detected."""
    job_id: str
    datacenter: str
    manager_id: str
    manager_host: str
    manager_port: int
    reason: str  # "timeout" | "stuck"
    elapsed_seconds: float
    fence_token: int
```

### JobGlobalTimeout

```python
@dataclass
class JobGlobalTimeout(Message):
    """Gate -> Manager: Global timeout declared."""
    job_id: str
    reason: str  # Why gate timed out the job
    timed_out_at: float  # Gate's timestamp
    fence_token: int  # Gate's fence token for this decision
```

---

## Part 7: Fault Tolerance Scenarios

### Scenario 1: Manager Leader Failure

```
Timeline:
T0: Leader-A tracking job timeout (started_at = 100.0)
T1: Leader-A fails
T2: Leader-B elected
T3: Leader-B receives job via state sync
T4: Leader-B calls resume_tracking()
     - Increments fence_token (1 -> 2)
     - Continues from started_at = 100.0 (preserved!)
T5: Leader-B continues timeout checking

Result: Timeout tracking continues seamlessly
```

**Key**: `started_at` in TimeoutTrackingState is absolute, preserved across transfers.

### Scenario 2: Gate Failure (Multi-DC)

```
Timeline:
T0: Gate tracking job across DC-A, DC-B, DC-C
T1: Gate fails
T2: Managers continue sending reports (stored in pending_reports)
T3: Gate restarts/replaced
T4: Managers resend pending timeout reports
T5: New gate reconstructs state from reports
T6: Gate declares global timeout

Fallback:
If gate down for 5+ minutes:
  - Managers timeout jobs locally (fallback)
  - Each DC independently marks job failed
```

**Key**: Managers have fallback to local timeout if gate unreachable.

### Scenario 3: Stale Global Timeout (After Leader Transfer)

```
Timeline:
T0: Leader-A (fence_token=1) reports timeout to gate
T1: Leader-A fails
T2: Leader-B takes over (fence_token=2)
T3: Gate sends JobGlobalTimeout(fence_token=1) [stale!]
T4: Leader-B receives message
     - Validates: 1 < 2 (stale)
     - Rejects message
     - Sends status correction to gate

Result: Stale timeout rejected, gate updates state
```

**Key**: Fence tokens prevent stale decisions.

---

## Part 8: Integration with AD-26 (Healthcheck Extensions)

### The Problem

**Worker extension requests (AD-26) and job timeouts (AD-34) must cooperate**. Currently, they operate independently, creating several critical issues:

#### Issue 1: Extension-Timeout Race Condition

```
Timeline:
T0:   Job starts (timeout_seconds = 300s)
T50:  Worker executing long workflow, requests extension (+15s granted)
T100: Worker requests 2nd extension (+7.5s granted)
T150: Worker requests 3rd extension (+3.75s granted)
T300: Job timeout fires!

Problem:
- Worker has 26.25s of legitimately granted extensions remaining
- Worker is making progress (each extension required progress)
- Job timeout doesn't account for extensions
- Job killed prematurely despite legitimate work
```

### Solution: Extension-Aware Timeout

AD-34 timeout tracking now includes comprehensive lifecycle management that cooperates with AD-26 healthcheck extensions:

1. Extensions are tracked in `TimeoutTrackingState.total_extensions_granted`
2. Timeout deadline calculation includes: `started_at + timeout_seconds + total_extensions_granted`
3. Progress from extensions is reported to timeout strategy

---

## Part 9: Files

| File | Purpose |
|------|---------|
| `distributed_rewrite/jobs/timeout_strategy.py` | TimeoutStrategy interface, LocalAuthorityTimeout, GateCoordinatedTimeout |
| `distributed_rewrite/models/jobs.py` | TimeoutTrackingState dataclass added to JobInfo |
| `distributed_rewrite/models/distributed.py` | JobProgressReport, JobTimeoutReport, JobGlobalTimeout, JobLeaderTransfer messages |
| `nodes/manager.py` | Strategy selection, unified timeout loop, leader transfer handling |
| `nodes/gate.py` | GateJobTracker, global timeout loop, broadcast coordination |
| `distributed_rewrite/workflow/state_machine.py` | Progress tracking integration (from AD-33) |

---

## Summary

AD-34 introduces **adaptive job timeout with multi-DC coordination** that:

- **Auto-detects topology** - Uses local authority (single-DC) or gate coordination (multi-DC)
- **Robust to failures** - Leader transfers, gate failures, network partitions
- **Race condition safe** - Fence tokens, timestamps, status corrections
- **Detects stuck workflows** - Progress tracking via AD-33 state machine
- **Global consistency** - Gate ensures timeout cancels job in ALL DCs
- **Fallback protection** - Managers timeout locally if gate unreachable (5 min)
- **Zero configuration** - Strategy chosen per-job based on `gate_addr`
- **State recovery** - Timeout state persists in JobInfo, survives leader transfers
- **Extension-aware** - Cooperates with AD-26 healthcheck extensions

This architecture ensures jobs never leak resources, even when workers are alive but workflows are stuck, across both single-datacenter and multi-datacenter deployments.
