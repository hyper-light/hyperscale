---
ad_number: 49
name: Workflow Context Propagation in Distributed Jobs
description: Enable context sharing between dependent workflows with fault-tolerant recovery
---

# AD-49: Workflow Context Propagation in Distributed Jobs

**Decision**: Implement workflow context propagation for distributed jobs using manager-managed per-sub-workflow context storage. Context flows Worker -> Manager -> Dependent Workflow, with recovery support when workers fail.

**Related**: AD-48 (Cross-Manager Worker Visibility), AD-33 (Federated Health Monitoring), AD-38 (Global Job Ledger)

**Rationale**:
- Non-test workflows provide context (via `@provide` hooks) that dependent workflows consume (via `@use` hooks)
- Local execution via `RemoteGraphManager` correctly propagates context between workflows
- Distributed execution via `WorkflowDispatcher` currently sends empty context `{}` to all workers
- When workers fail mid-execution, replacement workers need access to the same context
- Existing infrastructure (`JobInfo.context`, `SubWorkflowInfo`) can be extended for recovery

---

## Part 1: Problem Statement

### Current Issues

1. **Context from WorkflowFinalResult is DROPPED**: In `workflow_final_result` handler, `context_updates` field is ignored
2. **Two disconnected context stores**: `ManagerState._job_contexts` vs `JobInfo.context` are not synchronized
3. **No per-worker context tracking**: When a worker dies, there's no way to provide its context state to a replacement
4. **`requeue_workflow` not implemented**: Called in orphan scan but never defined

### Existing Structures We Leverage

| Structure | Location | Purpose |
|-----------|----------|---------|
| `SubWorkflowInfo` | `models/jobs.py` | Already tracks per-worker sub-workflow state, stores `result` |
| `JobInfo.context` | `models/jobs.py` | Already exists with `Context` type and `layer_version` |
| `Context.update()` | `core/state/context.py` | Already supports LWW with Lamport timestamps |
| `WorkflowFinalResult.context_updates` | `models/distributed.py` | Already serialized by worker, received by manager |

---

## Part 2: Architecture Overview

```
                        WORKFLOW CONTEXT PROPAGATION WITH RECOVERY
                        
  ┌─────────────────────────────────────────────────────────────────────────┐
  │                           JOB EXECUTION                                  │
  │                                                                          │
  │  ┌─────────────────────────────────────────────────────────────────┐    │
  │  │                    WORKFLOW A (Setup)                           │    │
  │  │              is_test=False, provides: {api_token, session_id}   │    │
  │  └───────────────────────────┬─────────────────────────────────────┘    │
  │                              │                                           │
  │                              │ (1) WorkflowFinalResult                   │
  │                              │     context_updates: {api_token, session} │
  │                              ▼                                           │
  │  ┌─────────────────────────────────────────────────────────────────┐    │
  │  │                    MANAGER (Job Leader)                          │    │
  │  │                                                                  │    │
  │  │   JobInfo:                                                       │    │
  │  │     context[workflow_a]: {api_token: "xyz", session_id: "abc"}  │    │
  │  │     layer_version: 1                                            │    │
  │  │                                                                  │    │
  │  │   SubWorkflowInfo[B:worker1]:                                   │    │
  │  │     dispatched_context: bytes  ← Stored for recovery            │    │
  │  │     dispatched_version: 1                                       │    │
  │  │                                                                  │    │
  │  └───────────────────────────┬─────────────────────────────────────┘    │
  │                              │                                           │
  │                              │ (2) WorkflowDispatch                      │
  │                              │     context: {api_token, session_id}      │
  │                              │     context_version: 1                    │
  │                              ▼                                           │
  │  ┌─────────────────────────────────────────────────────────────────┐    │
  │  │                    WORKFLOW B (Test)                             │    │
  │  │              is_test=True, depends_on: [WorkflowA]               │    │
  │  │              uses: {api_token, session_id}                       │    │
  │  └─────────────────────────────────────────────────────────────────┘    │
  │                                                                          │
  └─────────────────────────────────────────────────────────────────────────┘
```

---

## Part 3: Data Model Changes

### SubWorkflowInfo Enhancement

```python
@dataclass(slots=True)
class SubWorkflowInfo:
    token: TrackingToken
    parent_token: TrackingToken
    cores_allocated: int
    progress: WorkflowProgress | None = None
    result: WorkflowFinalResult | None = None
    
    # NEW: Context sent to worker (for recovery if worker dies)
    dispatched_context: bytes = b""
    dispatched_version: int = 0
```

**Why**: When a worker dies, we can re-dispatch to a new worker using the stored `dispatched_context` instead of recomputing from dependencies (which may have changed).

---

## Part 4: Context Flow - Normal Execution

```
┌─────────────────────────────────────────────────────────────────────────────┐
│  1. DISPATCH                                                                 │
│     - get_context_for_workflow() reads from JobInfo.context[dependency]     │
│     - Serialize context, store in SubWorkflowInfo.dispatched_context        │
│     - Send WorkflowDispatch to worker                                       │
├─────────────────────────────────────────────────────────────────────────────┤
│  2. EXECUTION                                                                │
│     - Worker executes with context                                          │
│     - Worker updates context via @provide hooks                             │
│     - Worker serializes context into WorkflowFinalResult.context_updates    │
├─────────────────────────────────────────────────────────────────────────────┤
│  3. COMPLETION                                                               │
│     - Manager receives WorkflowFinalResult                                  │
│     - apply_workflow_context() stores in JobInfo.context[workflow_name]     │
│     - Stores result in SubWorkflowInfo.result                               │
│     - Marks workflow complete, signals dependents                           │
├─────────────────────────────────────────────────────────────────────────────┤
│  4. DEPENDENT DISPATCH                                                       │
│     - Dependent workflow becomes ready                                      │
│     - get_context_for_workflow() reads completed workflow's context         │
│     - Context propagates to dependent workflow                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## Part 5: Context Flow - Worker Failure Recovery

```
┌─────────────────────────────────────────────────────────────────────────────┐
│  1. FAILURE DETECTION                                                        │
│     - SWIM detects worker as DEAD                                           │
│     - Orphan scan finds sub-workflow with no result                         │
├─────────────────────────────────────────────────────────────────────────────┤
│  2. CONTEXT RECOVERY                                                         │
│     - SubWorkflowInfo.dispatched_context contains what we sent              │
│     - SubWorkflowInfo.dispatched_version contains layer version             │
├─────────────────────────────────────────────────────────────────────────────┤
│  3. RE-DISPATCH                                                              │
│     - requeue_workflow() resets PendingWorkflow state                       │
│     - On next dispatch, check for existing SubWorkflowInfo with context     │
│     - If found and no result, use stored dispatched_context                 │
│     - New worker starts from same context as failed worker                  │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## Part 6: Implementation Details

### 6.1 JobManager Methods

```python
async def apply_workflow_context(
    self,
    job_id: str,
    workflow_name: str,
    context_updates_bytes: bytes,
) -> bool:
    """Apply context updates from completed workflow to job context."""
    if (job := self.get_job_by_id(job_id)) is None:
        return False
    
    context_updates = cloudpickle.loads(context_updates_bytes)
    
    async with job.lock:
        workflow_context = job.context[workflow_name]
        for key, value in context_updates.items():
            await workflow_context.set(key, value)
        job.layer_version += 1
        return True


async def set_sub_workflow_dispatched_context(
    self,
    sub_workflow_token: str | TrackingToken,
    context_bytes: bytes,
    layer_version: int,
) -> bool:
    """Store dispatched context for recovery."""
    token_str = str(sub_workflow_token)
    if (job := self.get_job_for_sub_workflow(token_str)) is None:
        return False
    
    async with job.lock:
        if sub_wf := job.sub_workflows.get(token_str):
            sub_wf.dispatched_context = context_bytes
            sub_wf.dispatched_version = layer_version
            return True
        return False
```

### 6.2 WorkflowDispatcher Changes

In `_dispatch_workflow()`:

```python
# Load context from dependencies
context_for_workflow = await self._job_manager.get_context_for_workflow(
    pending.job_id,
    pending.workflow_name,
    pending.dependencies,
)
context_bytes = _serialize_context(context_for_workflow)
layer_version = await self._job_manager.get_layer_version(pending.job_id)

# After successful dispatch, store for recovery
await self._job_manager.set_sub_workflow_dispatched_context(
    sub_token,
    context_bytes,
    layer_version,
)
```

### 6.3 Server Handler Update

In `workflow_final_result`:

```python
@tcp.receive()
async def workflow_final_result(self, addr, data, clock_time) -> bytes:
    result = WorkflowFinalResult.load(data)
    
    # Apply context updates to JobInfo.context
    if result.context_updates:
        await self._job_manager.apply_workflow_context(
            job_id=result.job_id,
            workflow_name=result.workflow_name,
            context_updates_bytes=result.context_updates,
        )
    
    # Existing completion logic...
```

### 6.4 Requeue with Context Recovery

```python
async def requeue_workflow(self, sub_workflow_token: str) -> bool:
    """Requeue orphaned sub-workflow with context recovery."""
    # Implementation handles context recovery from SubWorkflowInfo
```

---

## Part 7: Files Modified

| File | Change |
|------|--------|
| `models/jobs.py` | Add `dispatched_context`, `dispatched_version` to `SubWorkflowInfo` |
| `models/distributed.py` | Add `context_snapshot`, `layer_version` to `JobStateSyncMessage`; update `load_context()` return type |
| `jobs/job_manager.py` | Add `apply_workflow_context()`, `set_sub_workflow_dispatched_context()`, `get_context_for_workflow()`, `get_layer_version()` |
| `jobs/workflow_dispatcher.py` | Store dispatched context, implement `requeue_workflow()`, add `_serialize_context()` |
| `nodes/manager/server.py` | Call `apply_workflow_context()` in `workflow_final_result`; sync context in `_peer_job_state_sync_loop`; apply context in `job_state_sync` handler |

---

## Part 8: Design Principles

1. **Use existing structures**: Extend `SubWorkflowInfo` and `JobInfo.context`, don't create new ones
2. **Single source of truth**: `JobInfo.context` is authoritative for job context
3. **Recovery-ready**: Stored `dispatched_context` enables seamless worker recovery
4. **Asyncio compatible**: All context operations use async locks
5. **Low cyclomatic complexity**: Each method does one thing

---

## Part 9: Failure Modes

### Worker Dies Mid-Execution

- **Detection**: SWIM + orphan scan
- **Recovery**: Use `SubWorkflowInfo.dispatched_context` for replacement worker
- **Impact**: Workflow restarts from dispatch point, not from scratch

### Manager Crashes

- **Detection**: SWIM between managers
- **Recovery**: New leader has `JobInfo` from periodic `JobStateSyncMessage` (includes `context_snapshot` and `layer_version`)
- **Impact**: Context may be up to sync_interval stale, but workflow continues with last synced state

### Context Update Lost

- **Detection**: WorkflowFinalResult delivery failure
- **Recovery**: Existing TCP retry logic
- **Impact**: Dependent workflows delayed until context arrives

---

## Part 10: Anti-Patterns

**DO NOT**:
- Block on context sync before dispatch
- Require context for dispatch (context is optional)
- Store context in gossip buffer (too large)
- Use `_manager_state._job_contexts` (use `JobInfo.context` instead)

**DO**:
- Best-effort context loading (non-blocking)
- Dispatch proceeds even with empty context
- Store dispatched context for recovery
- Sync context to peers via `JobStateSyncMessage.context_snapshot`
- Use protocol-layer serialization (Message.dump/load handles cloudpickle)
