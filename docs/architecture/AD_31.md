---
ad_number: 31
name: Gossip-Informed Callbacks for Failure Propagation
description: Invoke application callbacks when learning about deaths via gossip for consistent cluster views
---

# AD-31: Gossip-Informed Callbacks for Failure Propagation

**Decision**: Invoke application-layer callbacks (`_on_node_dead_callbacks`) when SWIM gossip reports a node as dead, not just when direct failure detection occurs. This enables cluster-wide consistent failure response and proper job leadership transfer across all node relationships.

**Rationale**:
In a distributed system using SWIM protocol, failure detection can occur through two paths:
1. **Direct detection**: Node A probes Node B, timeout expires, A marks B dead
2. **Gossip propagation**: Node A learns from Node C's gossip that B is dead

The original implementation only invoked `_on_node_dead_callbacks` for direct detection. This caused inconsistent cluster views where nodes that learned about failures via gossip didn't update their application state (e.g., `_active_gate_peers`, job leadership tracking).

## Problem Statement - Inconsistent Failure Response

```
Scenario: 3-node gate cluster (Gate1, Gate2, Gate3)

T=0.0: Gate3 crashes
T=0.5: Gate1 directly detects Gate3 failure (probe timeout)
       -> _on_node_dead_callbacks invoked on Gate1
       -> Gate1._active_gate_peers removes Gate3 [checkmark]
       -> Gate1 takes over Gate3's job leadership [checkmark]

T=0.6: Gate1 gossips "Gate3 is DEAD" to Gate2
       -> Gate2.process_piggyback_data() receives update
       -> Gate2 updates incarnation_tracker to DEAD
       -> [X] _on_node_dead_callbacks NOT invoked on Gate2
       -> Gate2._active_gate_peers still contains Gate3!
       -> Gate2 doesn't know Gate3's jobs transferred to Gate1

Result: Gate2 has stale view - may route requests to dead Gate3
        or conflict with Gate1's job leadership takeover
```

## Solution: Gossip-Informed Callbacks

```
+-----------------------------------------------------------------------------+
|                    FAILURE DETECTION CALLBACK FLOW                          |
+-----------------------------------------------------------------------------+
|                                                                             |
|  PATH 1: DIRECT DETECTION                                                   |
|  ------------------------                                                   |
|                                                                             |
|  SWIM Probe Timeout                                                         |
|        |                                                                    |
|        v                                                                    |
|  start_suspicion(node)                                                      |
|        |                                                                    |
|        v                                                                    |
|  [Suspicion timer expires in TimingWheel]                                   |
|        |                                                                    |
|        v                                                                    |
|  _on_suspicion_expired(node)                                                |
|        |                                                                    |
|        +-> update_node_state(node, DEAD)                                    |
|        +-> queue_gossip_update('dead', node)    --> propagate to cluster    |
|        +-> invoke _on_node_dead_callbacks(node)  [checkmark]                |
|                                                                             |
|  PATH 2: GOSSIP-INFORMED (NEW)                                              |
|  -----------------------------                                              |
|                                                                             |
|  Receive gossip: "node X is DEAD"                                           |
|        |                                                                    |
|        v                                                                    |
|  process_piggyback_data(data)                                               |
|        |                                                                    |
|        +-> Check: was node already DEAD?                                    |
|        |          |                                                         |
|        |          +-> YES: skip (idempotent)                                |
|        |          |                                                         |
|        |          +-> NO: state transition detected                         |
|        |                   |                                                |
|        v                   |                                                |
|  update_node_state(node, DEAD)                                              |
|        |                   |                                                |
|        |                   v                                                |
|        |   invoke _on_node_dead_callbacks(node)  [checkmark] (NEW)          |
|        |                                                                    |
|        +-> queue_gossip_update('dead', node)    --> continue propagation    |
|                                                                             |
+-----------------------------------------------------------------------------+
```

## Key Implementation Details

1. **Idempotency**: Only invoke callbacks when state actually changes (NOT-DEAD -> DEAD)
2. **Symmetry**: Mirrors existing DEAD->OK recovery detection in `update_node_state`
3. **Incarnation respect**: Only process gossip with fresh incarnation numbers
4. **Metrics**: Track `gossip_informed_deaths` separately from direct detections

## Code Change (in `process_piggyback_data`)

```python
# Check previous state BEFORE updating
previous_state = self._incarnation_tracker.get_node_state(update.node)
was_dead = previous_state and previous_state.status == b'DEAD'

updated = self.update_node_state(update.node, status, update.incarnation, update.timestamp)

# Gossip-informed callback: invoke when learning about death via gossip
if updated and update.update_type in ('dead', 'leave') and not was_dead:
    self._metrics.increment('gossip_informed_deaths')
    self._probe_scheduler.remove_member(update.node)
    for callback in self._on_node_dead_callbacks:
        callback(update.node)
```

## Impact on Node Relationships

| Relationship | Before AD-31 | After AD-31 |
|--------------|--------------|-------------|
| Gate <-> Gate | Only detector updates `_active_gate_peers` | All gates update consistently |
| Manager <-> Manager | Only detector triggers job takeover | All managers see consistent state |
| Gate <-> Manager | Managers don't learn about gate failures quickly | Managers can react to gate deaths |
| Manager <-> Worker | Workers only react to direct detection | Workers respond to gossip too |

## Job Leadership Transfer Cascade

With gossip-informed callbacks, the failure propagation enables proper job leadership transfer:

```
Gate Failure -> Job Leadership Transfer
--------------------------------------
Gate1 (job leader) dies
    |
    +-> Gate2 detects (direct or gossip)
    |       +-> _on_node_dead callback
    |               +-> _handle_gate_peer_failure
    |                       +-> _handle_job_leader_failure
    |                               +-> takeover_leadership(job_id)
    |                               +-> _broadcast_job_leadership (to gates)
    |                               +-> _notify_managers_of_leadership (NEW)
    |
    +-> Gate3 detects (gossip from Gate2)
            +-> _on_node_dead callback
                    +-> Updates _active_gate_peers
                    +-> Sees Gate2 already took over (via broadcast)

Manager Failure -> Job Leadership Transfer
------------------------------------------
Manager1 (job leader in DC) dies
    |
    +-> Manager2 (cluster leader) detects
    |       +-> _on_node_dead callback
    |               +-> _handle_manager_peer_failure
    |                       +-> _handle_job_leader_failure
    |                               +-> Takes over job leadership
    |                               +-> Propagates via heartbeat
    |                               +-> _notify_gate_of_leadership (NEW)
    |                               +-> _notify_workers_of_leadership (NEW)
    |
    +-> Workers detect (gossip)
    |       +-> _on_node_dead callback
    |               +-> _handle_manager_failure
    |                       +-> Selects new primary manager
    |                       +-> Receives leadership update via heartbeat
    |
    +-> Origin Gate learns (via manager notification)
            +-> Updates _job_dc_managers[job_id][dc_id]
```

## Safeguards

1. **Incarnation checking**: Stale gossip with old incarnation is rejected
2. **State transition check**: Only fire callback on actual NOT-DEAD -> DEAD transition
3. **Fencing tokens**: Job leadership uses monotonic tokens to prevent stale leaders
4. **Idempotent handlers**: Application callbacks must handle duplicate invocations

## Testing Strategy

1. Unit test: Verify callbacks invoked for gossip-received deaths
2. Integration test: 3 gates, kill one, verify all gates update `_active_gate_peers`
3. Integration test: Job leadership transfers correctly when leader gate fails
4. Integration test: Manager cluster leader takes over jobs when non-leader fails
5. Integration test: Workers discover new job leader after manager failure

## Files Modified

- `hyperscale/distributed_rewrite/swim/health_aware_server.py`: Add gossip-informed callback invocation in `process_piggyback_data`
- `hyperscale/distributed_rewrite/nodes/gate.py`: Add manager notification after job leadership takeover
- `hyperscale/distributed_rewrite/nodes/manager.py`: Add gate and worker notification after job leadership takeover
